{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a prototype of the desired workflow of solving a QBAF that contains support links and nodes of topics and product."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from reasoner.models import CountinuousDFQuADModel\n",
    "from reasoner.solver import Solver\n",
    "from reasoner.utilities import Collector, Adaptor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>argument_id</th>\n",
       "      <th>chunk</th>\n",
       "      <th>topic</th>\n",
       "      <th>rank</th>\n",
       "      <th>polarity_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>I always get a half size up in my tennis shoes .</td>\n",
       "      <td>4</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>-0.166667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>For some reason these feel to big in the heel ...</td>\n",
       "      <td>15</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>-0.050000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>walked 3 hours with no problem</td>\n",
       "      <td>8</td>\n",
       "      <td>0.248569</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>Put them on and !</td>\n",
       "      <td>3</td>\n",
       "      <td>0.254298</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>Love them !</td>\n",
       "      <td>2</td>\n",
       "      <td>0.246981</td>\n",
       "      <td>0.625000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1193</th>\n",
       "      <td>369</td>\n",
       "      <td>I can wear the shoe all day long and</td>\n",
       "      <td>3</td>\n",
       "      <td>0.125414</td>\n",
       "      <td>-0.050000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1194</th>\n",
       "      <td>369</td>\n",
       "      <td>they are easy to clean compared to other shoes...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.126618</td>\n",
       "      <td>0.225000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1195</th>\n",
       "      <td>369</td>\n",
       "      <td>They are light colored so any dirt will be see...</td>\n",
       "      <td>18</td>\n",
       "      <td>0.126863</td>\n",
       "      <td>0.342857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1196</th>\n",
       "      <td>369</td>\n",
       "      <td>Would definitely buy another pair in a differe...</td>\n",
       "      <td>16</td>\n",
       "      <td>0.124921</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1197</th>\n",
       "      <td>370</td>\n",
       "      <td>Love these shoes !</td>\n",
       "      <td>23</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.625000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1198 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      argument_id                                              chunk  topic  \\\n",
       "0               0   I always get a half size up in my tennis shoes .      4   \n",
       "1               0  For some reason these feel to big in the heel ...     15   \n",
       "2               1                     walked 3 hours with no problem      8   \n",
       "3               1                                  Put them on and !      3   \n",
       "4               1                                        Love them !      2   \n",
       "...           ...                                                ...    ...   \n",
       "1193          369               I can wear the shoe all day long and      3   \n",
       "1194          369  they are easy to clean compared to other shoes...      0   \n",
       "1195          369  They are light colored so any dirt will be see...     18   \n",
       "1196          369  Would definitely buy another pair in a differe...     16   \n",
       "1197          370                                 Love these shoes !     23   \n",
       "\n",
       "          rank  polarity_score  \n",
       "0     0.500000       -0.166667  \n",
       "1     0.500000       -0.050000  \n",
       "2     0.248569        0.000000  \n",
       "3     0.254298        0.000000  \n",
       "4     0.246981        0.625000  \n",
       "...        ...             ...  \n",
       "1193  0.125414       -0.050000  \n",
       "1194  0.126618        0.225000  \n",
       "1195  0.126863        0.342857  \n",
       "1196  0.124921        0.000000  \n",
       "1197  1.000000        0.625000  \n",
       "\n",
       "[1198 rows x 5 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load data\n",
    "fpath = \"./data/chunks.csv\"\n",
    "chunks = pd.read_csv(fpath)\n",
    "chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>argument_id</th>\n",
       "      <th>chunk</th>\n",
       "      <th>topic</th>\n",
       "      <th>rank</th>\n",
       "      <th>polarity_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>walked 3 hours with no problem</td>\n",
       "      <td>8</td>\n",
       "      <td>0.248569</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Put them on and !</td>\n",
       "      <td>3</td>\n",
       "      <td>0.254298</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Love them !</td>\n",
       "      <td>2</td>\n",
       "      <td>0.246981</td>\n",
       "      <td>0.625000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>So light feeling</td>\n",
       "      <td>9</td>\n",
       "      <td>0.250153</td>\n",
       "      <td>0.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>excelente</td>\n",
       "      <td>-1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1191</th>\n",
       "      <td>369</td>\n",
       "      <td>I can wear the shoe all day long and</td>\n",
       "      <td>3</td>\n",
       "      <td>0.125414</td>\n",
       "      <td>-0.050000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1192</th>\n",
       "      <td>369</td>\n",
       "      <td>they are easy to clean compared to other shoes...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.126618</td>\n",
       "      <td>0.225000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1193</th>\n",
       "      <td>369</td>\n",
       "      <td>They are light colored so any dirt will be see...</td>\n",
       "      <td>18</td>\n",
       "      <td>0.126863</td>\n",
       "      <td>0.342857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1194</th>\n",
       "      <td>369</td>\n",
       "      <td>Would definitely buy another pair in a differe...</td>\n",
       "      <td>16</td>\n",
       "      <td>0.124921</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1195</th>\n",
       "      <td>370</td>\n",
       "      <td>Love these shoes !</td>\n",
       "      <td>23</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.625000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1196 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      argument_id                                              chunk  topic  \\\n",
       "0               1                     walked 3 hours with no problem      8   \n",
       "1               1                                  Put them on and !      3   \n",
       "2               1                                        Love them !      2   \n",
       "3               1                                   So light feeling      9   \n",
       "4               2                                          excelente     -1   \n",
       "...           ...                                                ...    ...   \n",
       "1191          369               I can wear the shoe all day long and      3   \n",
       "1192          369  they are easy to clean compared to other shoes...      0   \n",
       "1193          369  They are light colored so any dirt will be see...     18   \n",
       "1194          369  Would definitely buy another pair in a differe...     16   \n",
       "1195          370                                 Love these shoes !     23   \n",
       "\n",
       "          rank  polarity_score  \n",
       "0     0.248569        0.000000  \n",
       "1     0.254298        0.000000  \n",
       "2     0.246981        0.625000  \n",
       "3     0.250153        0.400000  \n",
       "4     1.000000        0.000000  \n",
       "...        ...             ...  \n",
       "1191  0.125414       -0.050000  \n",
       "1192  0.126618        0.225000  \n",
       "1193  0.126863        0.342857  \n",
       "1194  0.124921        0.000000  \n",
       "1195  1.000000        0.625000  \n",
       "\n",
       "[1196 rows x 5 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# remove all chunks of an review\n",
    "def remove_review_by_id(review_id, chunks):\n",
    "    result = chunks[chunks[\"argument_id\"] != review_id].reset_index(drop=True)\n",
    "    return result\n",
    "\n",
    "remove_review_by_id(0, chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create node and link dataframes\n",
    "def get_nodes(chunks):\n",
    "    topics = chunks[\"topic\"].unique().tolist()\n",
    "    topics.remove(-1)\n",
    "    topics.sort()\n",
    "    topics = [f\"Topic {t}\" for t in topics]\n",
    "    topics.append(\"Product\")\n",
    "    \n",
    "    chunk_text = chunks[\"chunk\"]\n",
    "    chunk_text = pd.concat([chunk_text, pd.Series(topics)], ignore_index=True)\n",
    "    \n",
    "    result = pd.DataFrame({\"chunk\": chunk_text}) \n",
    "    result[\"weight\"] = 0.5\n",
    "    return result\n",
    "\n",
    "def get_supports(chunks):\n",
    "    topic_index_start = max(chunks.index) + 1\n",
    "    topics = chunks[\"topic\"].unique().tolist()\n",
    "    topics.remove(-1)\n",
    "    topics.sort()\n",
    "    product_index = topic_index_start + len(topics)\n",
    "   \n",
    "    # add supports between chunks and topics\n",
    "    supports = chunks[chunks[\"polarity_score\"] >= 0]\n",
    "    supports = supports[supports[\"topic\"] != -1]\n",
    "    supports[\"chunk_id\"] = supports.index\n",
    "    supports = supports[[\"chunk_id\", \"topic\"]]\n",
    "    supports = supports.reset_index(drop=True)\n",
    "    supports[\"topic\"] += topic_index_start\n",
    "    supports = supports.rename(columns={\n",
    "        \"chunk_id\": \"source\", \n",
    "        \"topic\": \"target\"\n",
    "    })\n",
    "    \n",
    "    # add support between topics and product\n",
    "    new_rows = pd.DataFrame({\"source\": list(range(topic_index_start, topic_index_start + len(topics)))})\n",
    "    new_rows[\"target\"] = product_index\n",
    "    supports = pd.concat([supports, new_rows], ignore_index=True) \n",
    "    supports = supports.astype(int)\n",
    "    return supports\n",
    "\n",
    "def get_attacks(chunks):\n",
    "    topic_index_start = max(chunks.index) + 1\n",
    "   \n",
    "    # add supports between chunks and topics\n",
    "    attacks = chunks[chunks[\"polarity_score\"] < 0]\n",
    "    attacks = attacks[attacks[\"topic\"] != -1]\n",
    "    attacks[\"chunk_id\"] = attacks.index\n",
    "    attacks = attacks[[\"chunk_id\", \"topic\"]]\n",
    "    attacks = attacks.reset_index(drop=True)\n",
    "    attacks[\"topic\"] += topic_index_start\n",
    "    attacks = attacks.rename(columns={\n",
    "        \"chunk_id\": \"source\", \n",
    "        \"topic\": \"target\"\n",
    "    })\n",
    "    attacks = attacks.astype(int)\n",
    "    return attacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build adaptor of input data\n",
    "nodes = get_nodes(chunks)\n",
    "supports = get_supports(chunks)\n",
    "attacks = get_attacks(chunks)\n",
    "\n",
    "adaptor = Adaptor(arguments=nodes, weight_col=\"weight\", attacks=attacks, supports=supports)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build solver\n",
    "model = CountinuousDFQuADModel(data_adaptor=adaptor)\n",
    "solver = Solver(model=model, step_size=0.5, max_steps=10e4, epsilon=10e-4)\n",
    "final_step, collector = solver.solve(solver=\"RK4\", collect_data=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0.50097466, 0.56237793, 0.62475586, 0.50012183, 0.50000001,\n",
       "        0.74951172, 0.74951172, 0.53118896, 0.50024366, 0.62475586,\n",
       "        0.99902344, 0.56237793, 0.74951172, 0.51559445, 0.74951172,\n",
       "        0.50000001, 0.53118896, 0.51559448, 0.74951172, 0.53117374,\n",
       "        0.62475586, 0.50779723, 0.7495116 , 0.62475491, 0.56231701]),\n",
       " 0.9990234374890825)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_prod_strength = model.strength_vector[-1]\n",
    "model.strength_vector[-26:-1], model.strength_vector[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Remove review #0, covergence reached at step 8: [0.50097466 0.56237793 0.62475586 0.50012183 0.50000003 0.74951172\n",
      " 0.74951172 0.53118896 0.50024366 0.62475586 0.99902344 0.56237793\n",
      " 0.74951172 0.51559445 0.74951172 0.50000001 0.53118896 0.51559448\n",
      " 0.74951172 0.53117374 0.62475586 0.50779723 0.7495116  0.62475491\n",
      " 0.56231701], 0.9990234374890825\n",
      "Remove review #154, covergence reached at step 8: [0.50097466 0.56237793 0.62475586 0.50012183 0.50000001 0.74951172\n",
      " 0.74951172 0.53118896 0.50024366 0.62475586 0.99902344 0.56237793\n",
      " 0.74951172 0.51559445 0.74951172 0.50000001 0.53118896 0.51559448\n",
      " 0.74951172 0.53117374 0.62475586 0.50779723 0.7495116  0.62475396\n",
      " 0.56231701], 0.9990234374890825\n",
      "Remove review #155, covergence reached at step 8: [0.50097466 0.56237793 0.62475586 0.50012183 0.50000001 0.74951172\n",
      " 0.74951172 0.53118896 0.50024366 0.62475586 0.99902344 0.56237793\n",
      " 0.74951172 0.51559445 0.74951172 0.50000001 0.53118896 0.51559448\n",
      " 0.74951172 0.53117374 0.62475586 0.50779721 0.7495116  0.62475491\n",
      " 0.56213427], 0.9990234374890816\n"
     ]
    }
   ],
   "source": [
    "result = []\n",
    "for i in [0, 154, 155]:\n",
    "    part_chunks = remove_review_by_id(i, chunks)\n",
    "    nodes = get_nodes(part_chunks)\n",
    "    supports = get_supports(part_chunks)\n",
    "    attacks = get_attacks(part_chunks)\n",
    "    adaptor = Adaptor(arguments=nodes, weight_col=\"weight\", attacks=attacks, supports=supports)\n",
    "    model = CountinuousDFQuADModel(data_adaptor=adaptor)\n",
    "    solver = Solver(model=model, step_size=0.5, max_steps=10e4, epsilon=10e-4)\n",
    "    final_step, _ = solver.solve(solver=\"RK4\", collect_data=False)\n",
    "    print(f\"Remove review #{i}, covergence reached at step {final_step}: {model.strength_vector[-26:-1]}, {model.strength_vector[-1]}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
